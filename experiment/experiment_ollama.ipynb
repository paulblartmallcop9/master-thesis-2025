{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment LLM using Ollama\n"
      ],
      "metadata": {
        "id": "AAvNB0rn28Xe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup Ollama"
      ],
      "metadata": {
        "id": "IiDyhlbC3Ar0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dy81Hy6WuWrf"
      },
      "outputs": [],
      "source": [
        "!sudo apt update\n",
        "!sudo apt install -y pciutils\n",
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import subprocess\n",
        "import time\n",
        "\n",
        "def run_ollama_serve():\n",
        "    subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "thread = threading.Thread(target=run_ollama_serve)\n",
        "thread.start()\n",
        "time.sleep(5)"
      ],
      "metadata": {
        "id": "O1bfB74nuo1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-ollama"
      ],
      "metadata": {
        "id": "PFXuqDsTvCxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pull model"
      ],
      "metadata": {
        "id": "yaT0zrex3pQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!ollama pull gemma3 # set model"
      ],
      "metadata": {
        "id": "f2V7H9sg00xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt categories"
      ],
      "metadata": {
        "id": "6w4rxyqZ31g9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero-shot category\n",
        "def prompt_zero_shot(puzzle):\n",
        "    return f\"\"\"Los het volgende taalkundige raadsel op. Het bevat drie aanwijzingen en het antwoord is één woord dat op alle drie van toepassing is. Geef het antwoord op de eerste regel en daarna een korte uitleg.\n",
        "\n",
        "Vraag: {puzzle}. Wat is het?\n",
        "Antwoord:\"\"\"\n",
        "\n",
        "# One-shot category\n",
        "def prompt_one_shot(puzzle):\n",
        "    return f\"\"\"Los het volgende taalkundige raadsel op. Het bevat drie aanwijzingen en het antwoord is één woord dat op alle drie van toepassing is. Geef het antwoord op de eerste regel en daarna een korte uitleg. Eerst een voorbeeld, daarna een nieuw raadsel.\n",
        "\n",
        "Voorbeeld:\n",
        "Vraag: Het is een onderdeel van een schip, een bevestigingsmiddel, en een gymnastiekoefening. Wat is het?\n",
        "Antwoord: Schroef.\n",
        "\n",
        "Nu het raadsel:\n",
        "Vraag: {puzzle}. Wat is het?\n",
        "Antwoord:\"\"\"\n",
        "\n",
        "# Three-shot category\n",
        "def prompt_three_shot(puzzle):\n",
        "    return f\"\"\"Los het volgende taalkundige raadsel op. Het bevat drie aanwijzingen en het antwoord is één woord dat op alle drie van toepassing is. Geef het antwoord op de eerste regel en daarna een korte uitleg. Eerst drie voorbeelden, dan een nieuw raadsel.\n",
        "\n",
        "Voorbeeld 1:\n",
        "Vraag: Het is een onderdeel van een schip, een bevestigingsmiddel, en een gymnastiekoefening. Wat is het?\n",
        "Antwoord: Schroef.\n",
        "\n",
        "Voorbeeld 2:\n",
        "Vraag: Het is een winkelketen, een beroep, en een onderdeel van een schip. Wat is het?\n",
        "Antwoord: Zeeman.\n",
        "\n",
        "Voorbeeld 3:\n",
        "Vraag: Het is seksuele anatomie, een beledigend woord, en een vrucht. Wat is het?\n",
        "Antwoord: Eikel.\n",
        "\n",
        "Raadsel:\n",
        "Vraag: {puzzle}. Wat is het?\n",
        "Antwoord:\"\"\""
      ],
      "metadata": {
        "id": "4IUb3nhI30qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define files"
      ],
      "metadata": {
        "id": "CmUMx1Ry4GPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# File used for experiment\n",
        "infile = \"test_puzzles.txt\" # set infile\n",
        "\n",
        "# File used to save results\n",
        "outfile = \"results_test.txt\" # set infile"
      ],
      "metadata": {
        "id": "7z7L54OT4F7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Ollama"
      ],
      "metadata": {
        "id": "_xuHs38_4OVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_ollama.llms import OllamaLLM\n",
        "import ast\n",
        "\n",
        "\n",
        "# Read file\n",
        "def getData(file):\n",
        "    f = open(file, \"r\")\n",
        "    pages = f.readlines()\n",
        "    return pages\n",
        "\n",
        "# Write file\n",
        "def writeData(file, data):\n",
        "    with open(file, 'w') as f:\n",
        "        for line in data:\n",
        "            f.write(f\"{line}\\n\")\n",
        "\n",
        "# Load data from infile\n",
        "data = getData(infile)\n",
        "\n",
        "# Setup model\n",
        "template = \"\"\"Question: {question}\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "model = OllamaLLM(model=\"gemma3\") # set model\n",
        "chain = prompt | model\n",
        "\n",
        "results = []\n",
        "correct = 0\n",
        "for i, page in enumerate(data):\n",
        "    load = ast.literal_eval(page)\n",
        "    puzzle = load[\"prompt\"]\n",
        "    answer = load[\"answer\"]\n",
        "\n",
        "    # Set prompt category\n",
        "    prompt = prompt_three_shot(puzzle) # set shot category\n",
        "\n",
        "    print(f\"Processing: {i+1}/{len(data)}\")\n",
        "\n",
        "    # Generate output\n",
        "    result = chain.invoke({\"question\": prompt})\n",
        "\n",
        "    # Evaluate result\n",
        "    if answer.lower() in result.lower():\n",
        "        correct += 1\n",
        "\n",
        "    results.append({\"prompt\": prompt, \"answer\": answer, \"result\": result})\n",
        "\n",
        "print(f\"Correct: {correct}/{len(data)}\")\n",
        "\n",
        "# Export results\n",
        "writeData(outfile, results)"
      ],
      "metadata": {
        "id": "b3H5Sup0vI70"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
