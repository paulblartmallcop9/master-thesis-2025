{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Experiment LLM using HuggingFace"
      ],
      "metadata": {
        "id": "b9xXsFMS6RGM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate sentencepiece"
      ],
      "metadata": {
        "id": "XxlZQwKfFN1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Prompt categories"
      ],
      "metadata": {
        "id": "u3Vv3bTy6R2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Zero-shot category\n",
        "def prompt_zero_shot(puzzle):\n",
        "    return f\"\"\"Los het volgende taalkundige raadsel op. Het bevat drie aanwijzingen en het antwoord is één woord dat op alle drie van toepassing is. Geef het antwoord op de eerste regel en daarna een korte uitleg.\n",
        "\n",
        "Vraag: {puzzle}. Wat is het?\n",
        "Antwoord:\"\"\"\n",
        "\n",
        "# One-shot category\n",
        "def prompt_one_shot(puzzle):\n",
        "    return f\"\"\"Los het volgende taalkundige raadsel op. Het bevat drie aanwijzingen en het antwoord is één woord dat op alle drie van toepassing is. Geef het antwoord op de eerste regel en daarna een korte uitleg. Eerst een voorbeeld, daarna een nieuw raadsel.\n",
        "\n",
        "Voorbeeld:\n",
        "Vraag: Het is een onderdeel van een schip, een bevestigingsmiddel, en een gymnastiekoefening. Wat is het?\n",
        "Antwoord: Schroef.\n",
        "\n",
        "Nu het raadsel:\n",
        "Vraag: {puzzle}. Wat is het?\n",
        "Antwoord:\"\"\"\n",
        "\n",
        "# Three-shot category\n",
        "def prompt_three_shot(puzzle):\n",
        "    return f\"\"\"Los het volgende taalkundige raadsel op. Het bevat drie aanwijzingen en het antwoord is één woord dat op alle drie van toepassing is. Geef het antwoord op de eerste regel en daarna een korte uitleg. Eerst drie voorbeelden, dan een nieuw raadsel.\n",
        "\n",
        "Voorbeeld 1:\n",
        "Vraag: Het is een onderdeel van een schip, een bevestigingsmiddel, en een gymnastiekoefening. Wat is het?\n",
        "Antwoord: Schroef.\n",
        "\n",
        "Voorbeeld 2:\n",
        "Vraag: Het is een winkelketen, een beroep, en een onderdeel van een schip. Wat is het?\n",
        "Antwoord: Zeeman.\n",
        "\n",
        "Voorbeeld 3:\n",
        "Vraag: Het is seksuele anatomie, een beledigend woord, en een vrucht. Wat is het?\n",
        "Antwoord: Eikel.\n",
        "\n",
        "Raadsel:\n",
        "Vraag: {puzzle}. Wat is het?\n",
        "Antwoord:\"\"\""
      ],
      "metadata": {
        "id": "nl_lyz2T6Rok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define files"
      ],
      "metadata": {
        "id": "sPyzs-q96eiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# File used for experiment\n",
        "infile = \"test_puzzles.txt\" # set infile\n",
        "\n",
        "# File used to save results\n",
        "outfile = \"results_test.txt\" # set infile"
      ],
      "metadata": {
        "id": "-sDvXhRr6eIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run experiment"
      ],
      "metadata": {
        "id": "iJHSL2QP7GSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "\n",
        "\n",
        "# Read file\n",
        "def getData(file):\n",
        "    with open(file, \"r\") as f:\n",
        "        return f.readlines()\n",
        "\n",
        "# Write file\n",
        "def writeData(file, data):\n",
        "    with open(file, \"w\") as f:\n",
        "        for line in data:\n",
        "            f.write(f\"{line}\\n\")\n",
        "\n",
        "# Load data\n",
        "data = getData(infile)\n",
        "\n",
        "# Setup model\n",
        "model_name = \"BramVanroy/fietje-2-chat\" # set model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=0)\n",
        "\n",
        "results = []\n",
        "correct = 0\n",
        "for i, page in enumerate(data):\n",
        "    load = ast.literal_eval(page)\n",
        "    puzzle = load[\"prompt\"]\n",
        "    answer = load[\"answer\"]\n",
        "\n",
        "    # Set prompt category\n",
        "    prompt = prompt_zero_shot(puzzle) # set shot category\n",
        "\n",
        "    print(f\"Processing: {i+1}/{len(data)}\")\n",
        "\n",
        "    # Generate output\n",
        "    output = generator(prompt, max_new_tokens=50, do_sample=True, top_k=50, top_p=0.95)\n",
        "    result = output[0][\"generated_text\"]\n",
        "\n",
        "    # Evaluate result\n",
        "    if answer.lower() in result.lower():\n",
        "        correct += 1\n",
        "\n",
        "    results.append(str({\"prompt\": prompt, \"answer\": answer, \"result\": result}))\n",
        "\n",
        "print(f\"Correct: {correct}/{len(data)}\")\n",
        "\n",
        "# Export results\n",
        "writeData(outfile, results)"
      ],
      "metadata": {
        "id": "Y78_wDrMHJ77"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
